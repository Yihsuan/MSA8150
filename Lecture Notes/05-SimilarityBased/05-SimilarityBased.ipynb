{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Display figures in iPython notebook\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity-based Learning\n",
    "### References\n",
    "1. Zhitao Yin gave a great introduction to text mining https://github.com/zhitaoyin/GSU-Text-Mining-Workshop-Fall-2015 \n",
    "1. Scikit-Learn online documentation http://scikit-learn.org/stable/documentation.html\n",
    "1. scikit-learn Cookbook http://it-ebooks.info/book/4664/\n",
    "1. Mastering Machine Learning with scikit-learn http://it-ebooks.info/book/4315/\n",
    "2. Classification of text documents using sparse features http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing things from scratch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.8309518948453007"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## most primitive Euclidian distance\n",
    "def distance(vect1, vect2):\n",
    "    s = 0\n",
    "    for i in range(0, len(vect1)):\n",
    "        delta = vect1[i]-vect2[i]\n",
    "        s += delta*delta\n",
    "    return sqrt(s)\n",
    "\n",
    "distance([1, 2, 3], [-4, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## most primitive k-NN X=samples, q=query, k=number of neighbors\n",
    "def kNN(X, q, k):\n",
    "    d = []\n",
    "    for j in range(0, len(X)):\n",
    "        dis = distance(q, X[j])\n",
    "        d.append( ( dis, j) )\n",
    "\n",
    "    d = sorted(d, key=lambda tp: tp[0])\n",
    "    res = []\n",
    "    for i in range(0, k):\n",
    "        res.append(d[i][1])\n",
    "    return res, d[:k]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([205, 363, 75],\n",
       " [(0.42576209032351103, 205),\n",
       "  (0.44206281753670074, 363),\n",
       "  (0.6180533783262494, 75)])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = rand(1000,10)\n",
    "q = rand(10)\n",
    "kNN(data, q, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 32.249 seconds\n"
     ]
    }
   ],
   "source": [
    "## let's try this out on a really big set\n",
    "import time\n",
    "\n",
    "data = rand(10000,10000)\n",
    "q = rand(10000)\n",
    "\n",
    "t0 = time.time()\n",
    "kNN(data, q, 3)\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"This took %.3f seconds\" % (t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps are from Zhitao's example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import matplotlib package to plot figures\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import seaborn package to make figrures look better\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import pandas package to store and manipulate data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import numpy and scipy packages to do scientific analysis\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import csv package to convert pandas dataframe to csv file\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import chain package to do iteration \n",
    "from itertools import chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Counter package to do counting\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import operator package to sort a dictionary by its values\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import re package to implement regular expression\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import timer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import topic model packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import ldamodel;\n",
    "from gensim import matutils;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import NLTK package\n",
    "from nltk import sent_tokenize,word_tokenize,porter\n",
    "from nltk import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example from Scikit-Learn\n",
    "\n",
    "modified code from http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "#         Lars Buitinck <L.J.Buitinck@uva.nl>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "##from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "#from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.svm import LinearSVC\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "#from sklearn.linear_model import Perceptron\n",
    "#from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "#from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "class Option(object):\n",
    "    pass\n",
    "    \n",
    "opts = Option()\n",
    "\n",
    "#\"Print a detailed classification report.\"\n",
    "opts.print_report = True\n",
    "\n",
    "#\"Select some number of features using a chi-squared test\"\n",
    "opts.select_chi2 = 3\n",
    "\n",
    "\n",
    "#\"Print the confusion matrix.\")\n",
    "opts.print_cm = True\n",
    "\n",
    "#\"Print ten most discriminative terms per class for every classifier.\"\n",
    "opts.print_top10=False\n",
    "\n",
    "#\"Whether to use all categories or not.\"\n",
    "opts.all_categories = True\n",
    "\n",
    "#\"Use a hashing vectorizer.\"\n",
    "opts.use_hashing = True\n",
    "\n",
    "#\"n_features when using the hashing vectorizer.\"\n",
    "opts.n_features = 2 ** 16\n",
    "\n",
    "#\"Remove newsgroup information that is easily overfit: headers, signatures, and quoting.\"\n",
    "opts.filtered = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Load some categories from the training set\n",
    "if opts.all_categories:\n",
    "    categories = None\n",
    "else:\n",
    "    categories = [\n",
    "        'alt.atheism',\n",
    "        'talk.religion.misc',\n",
    "        'comp.graphics',\n",
    "        'sci.space',\n",
    "    ]\n",
    "\n",
    "if opts.filtered:\n",
    "    remove = ('headers', 'footers', 'quotes')\n",
    "else:\n",
    "    remove = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "all\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories if categories else \"all\")\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)\n",
    "print('data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314 documents - 13.782MB (training set)\n",
      "7532 documents - 8.262MB (test set)\n",
      "20 categories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categories = data_train.target_names    # for case categories == None\n",
    "\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
    "\n",
    "data_train_size_mb = size_mb(data_train.data)\n",
    "data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "    len(data_train.data), data_train_size_mb))\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "    len(data_test.data), data_test_size_mb))\n",
    "print(\"%d categories\" % len(categories))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training data using a sparse vectorizer\n",
      "done in 1.579269s at 8.727MB/s\n",
      "n_samples: 11314, n_features: 65536\n",
      "\n",
      "Extracting features from the test data using the same vectorizer\n",
      "done in 0.940218s at 8.787MB/s\n",
      "n_samples: 7532, n_features: 65536\n",
      "\n",
      "Extracting 3 best features by a chi-squared test\n",
      "done in 0.085701s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split a training set and a test set\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "\n",
    "### use hashing?\n",
    "if opts.use_hashing:\n",
    "    vectorizer = HashingVectorizer(stop_words='english', non_negative=True,\n",
    "                                   n_features=opts.n_features)\n",
    "    X_train = vectorizer.transform(data_train.data)\n",
    "else:\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "    X_train = vectorizer.fit_transform(data_train.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()\n",
    "\n",
    "\n",
    "# mapping from integer feature name to original token string\n",
    "if opts.use_hashing:\n",
    "    feature_names = None\n",
    "else:\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "if opts.select_chi2:\n",
    "    print(\"Extracting %d best features by a chi-squared test\" %\n",
    "          opts.select_chi2)\n",
    "    t0 = time()\n",
    "    ch2 = SelectKBest(chi2, k=opts.select_chi2)\n",
    "    X_train = ch2.fit_transform(X_train, y_train)\n",
    "    X_test = ch2.transform(X_test)\n",
    "    if feature_names:\n",
    "        # keep selected feature names\n",
    "        feature_names = [feature_names[i] for i\n",
    "                         in ch2.get_support(indices=True)]\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "\n",
    "\n",
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if opts.print_top10 and feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, category in enumerate(categories):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\"\n",
    "                      % (category, \" \".join(feature_names[top10]))))\n",
    "        print()\n",
    "\n",
    "    if opts.print_report:\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_test, pred,\n",
    "                                            target_names=categories))\n",
    "\n",
    "    if opts.print_cm:\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_neighbors=10, p=2, weights='uniform')\n",
      "train time: 0.001s\n",
      "test time:  1.413s\n",
      "accuracy:   0.107\n",
      "classification report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.14      0.01      0.02       319\n",
      "           comp.graphics       0.48      0.03      0.05       389\n",
      " comp.os.ms-windows.misc       0.57      0.46      0.51       394\n",
      "comp.sys.ibm.pc.hardware       0.05      0.90      0.10       392\n",
      "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
      "          comp.windows.x       0.26      0.02      0.03       395\n",
      "            misc.forsale       0.12      0.00      0.01       390\n",
      "               rec.autos       0.00      0.00      0.00       396\n",
      "         rec.motorcycles       0.00      0.00      0.00       398\n",
      "      rec.sport.baseball       0.00      0.00      0.00       397\n",
      "        rec.sport.hockey       0.00      0.00      0.00       399\n",
      "               sci.crypt       0.00      0.00      0.00       396\n",
      "         sci.electronics       0.00      0.00      0.00       393\n",
      "                 sci.med       0.00      0.00      0.00       396\n",
      "               sci.space       0.00      0.00      0.00       394\n",
      "  soc.religion.christian       0.48      0.38      0.43       398\n",
      "      talk.politics.guns       1.00      0.00      0.01       364\n",
      "   talk.politics.mideast       0.91      0.23      0.37       376\n",
      "      talk.politics.misc       0.00      0.00      0.00       310\n",
      "      talk.religion.misc       0.35      0.03      0.05       251\n",
      "\n",
      "             avg / total       0.21      0.11      0.08      7532\n",
      "\n",
      "confusion matrix:\n",
      "[[  3   0   0 247   0   0   0   0   0   0   0   0   0   0   0  64   0   1\n",
      "    0   4]\n",
      " [  0  10  18 351   0   9   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  0   5 183 202   0   1   3   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0  34 353   0   3   2   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   0   3 378   0   1   0   0   0   0   0   0   0   0   0   1   0   0\n",
      "    0   1]\n",
      " [  0   3  52 330   0   7   1   0   0   0   0   0   0   0   0   1   0   1\n",
      "    0   0]\n",
      " [  0   0  10 375   0   2   1   0   0   0   0   0   0   0   0   2   0   0\n",
      "    0   0]\n",
      " [  0   0   7 387   0   2   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0 394   0   0   0   0   0   0   0   0   0   0   0   4   0   0\n",
      "    0   0]\n",
      " [  0   0   0 392   0   0   0   0   0   0   0   0   0   0   0   5   0   0\n",
      "    0   0]\n",
      " [  0   0   1 394   0   0   0   0   0   0   0   0   0   0   0   4   0   0\n",
      "    0   0]\n",
      " [  0   0   2 390   0   0   0   0   1   0   0   0   0   0   0   3   0   0\n",
      "    0   0]\n",
      " [  0   0   5 386   0   1   0   0   0   0   0   0   0   0   0   1   0   0\n",
      "    0   0]\n",
      " [  1   0   0 384   0   1   0   0   0   0   0   0   0   0   0   9   0   0\n",
      "    0   1]\n",
      " [  0   0   1 388   0   0   1   0   0   0   0   0   0   0   0   3   0   1\n",
      "    0   0]\n",
      " [ 11   0   1 223   0   0   0   0   0   0   0   0   0   0   0 153   0   4\n",
      "    0   6]\n",
      " [  1   1   2 352   0   0   0   0   0   0   0   0   0   0   0   6   1   1\n",
      "    0   0]\n",
      " [  0   1   0 280   0   0   0   0   0   0   0   0   0   0   0   9   0  86\n",
      "    0   0]\n",
      " [  0   1   2 300   0   0   0   0   0   0   0   0   0   0   0   6   0   0\n",
      "    0   1]\n",
      " [  4   0   1 192   0   0   0   0   0   0   0   0   0   0   0  47   0   0\n",
      "    0   7]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "results = benchmark(KNeighborsClassifier(n_neighbors=10))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
